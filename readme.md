# Capstone Project

This project demonstrates a complete ETL (Extract, Transform, Load) pipeline using Python and C#. The objective is to simulate a real-world data engineering scenario where raw construction project data is collected, cleaned, transformed, loaded into another system, and finally analyzed.

## Objective

- Implement a multi-language ETL workflow
- Automate data transformation and system integration
- Simulate a realistic data reporting process using SQL

## Pipeline Phases

**Phase 1: Data Collection and Cleaning (Python)**  
Raw data is collected in CSV format. Python scripts are used to analyze, clean, and prepare the data for further processing.

**Phase 2: Data Transformation and Loading (C#)**  
Cleaned data is loaded into a new system, such as a SQLite database or XML file, simulating integration with external systems.

**Phase 3: Querying and Analysis (SQL)**  
SQL queries are used to extract meaningful insights and summarize key metrics from the loaded data.

**Phase 4: Reporting and Presentation**  
The final outputs, including summaries and reports, are generated and stored for review or decision-making.

## Technologies Used

- Python (pandas, CSV processing)
- C# (.NET Core for data transfer simulation)
- SQLite (for lightweight database simulation)
- SQL (for data querying and reporting)
- Git (version control)
